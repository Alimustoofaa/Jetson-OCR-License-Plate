{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "orig_nbformat": 4,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.6.9 64-bit"
  },
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "'''\n",
    "@author     : Ali Mustofa HALOTEC\n",
    "@module     : OCR License Plate Indonesia\n",
    "@Created on : 7 Agust 2021\n",
    "'''\n",
    "\n",
    "import sys\n",
    "import cv2\n",
    "import torch\n",
    "import easyocr\n",
    "from PIL import Image, ImageDraw\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "from src.schema.config_ocr import ConfigOcr\n",
    "from src.app import LicensePlateDetection\n",
    "from src.app import OpticalCharacterRecognition\n",
    "from config import KODE_WILAYAH_JSON\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OpticalCharacterRecognition:\n",
    "    '''\n",
    "    Load model library Ocr\n",
    "    '''\n",
    "    def __init__(self):\n",
    "        self.device = True if torch.cuda.is_available() else False\n",
    "        self.list_langs = ['en', 'id', 'la']\n",
    "        self.recog_network = 'latin_g2'\n",
    "        self.reader = easyocr.Reader(self.list_langs, gpu=self.device, recog_network=self.recog_network)\n",
    "\n",
    "    def detect_char(self, image):\n",
    "        '''\n",
    "        Detection character in image\n",
    "        Args:\n",
    "            image(np.array): image for detect character\n",
    "        Retrun:\n",
    "            result(list): [[x_min, x_max, y_min, y_max]], []\n",
    "        '''\n",
    "        return self.reader.detect(image)\n",
    "\n",
    "    def ocr_image(self, image, config):\n",
    "        '''\n",
    "        Read text in image with library easy ocr\n",
    "        with configuration in param config\n",
    "        Args:\n",
    "            image(np.array): image for ocr\n",
    "            config(schema.config_ocr): configuration library ocr\n",
    "        Retrun\n",
    "        '''\n",
    "        results = self.reader.readtext(\n",
    "            image,\n",
    "            detail          = config.detail,\n",
    "            decoder         = config.decoder,\n",
    "            beamWidth       = config.beam_width,\n",
    "            batch_size      = config.batch_size,\n",
    "            workers         = config.workers,\n",
    "            allowlist       = config.allow_list,\n",
    "            blocklist       = config.blocklist,\n",
    "            paragraph       = config.paragraph,\n",
    "            min_size        = config.min_size,\n",
    "            rotation_info   = config.rotation_info,\n",
    "            # Contrast\n",
    "            contrast_ths    = config.contrast_ths,\n",
    "            adjust_contrast = config.adjust_contrast,\n",
    "            # Text detection\n",
    "            text_threshold  = config.text_threshold + 0.1 if self.device else config.text_threshold,\n",
    "            low_text        = config.low_text,\n",
    "            link_threshold  = config.link_threshold,\n",
    "            canvas_size     = config.canvas_size,\n",
    "            mag_ratio       = config.mag_ratio\n",
    "        )\n",
    "        return results\n",
    "    \n",
    "    def draw_boxes(self, image, bounds, color='yellow', width=2):\n",
    "        text = []\n",
    "        confidence = []\n",
    "        image = Image.fromarray(cv2.cvtColor(image,cv2.COLOR_BGR2RGB))\n",
    "        draw = ImageDraw.Draw(image)\n",
    "\n",
    "        for bound in bounds:\n",
    "            if bound[2] > 0.0:\n",
    "                confidence.append(bound[2])\n",
    "                text.append(bound[1])\n",
    "                p0, p1, p2, p3 = bound[0]\n",
    "                draw.line([*p0, *p1, *p2, *p3, *p0], fill=color, width=width)\n",
    "        \n",
    "        # Calculate AVG confidence level\n",
    "        avgConf = sum(confidence)/len(confidence)\n",
    "        return image, text, avgConf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Load model_license_plate_iso_code.pt detection model.\n",
      "Using cache found in /home/ocr/.cache/torch/hub/ultralytics_yolov5_master\n",
      "\n",
      "                 from  n    params  module                                  arguments                     \n",
      "  0                -1  1      3520  models.common.Focus                     [3, 32, 3]                    \n",
      "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
      "  2                -1  1     19904  models.common.BottleneckCSP             [64, 64, 1]                   \n",
      "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
      "  4                -1  1    161152  models.common.BottleneckCSP             [128, 128, 3]                 \n",
      "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
      "  6                -1  1    641792  models.common.BottleneckCSP             [256, 256, 3]                 \n",
      "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
      "  8                -1  1    656896  models.common.SPP                       [512, 512, [5, 9, 13]]        \n",
      "  9                -1  1   1248768  models.common.BottleneckCSP             [512, 512, 1, False]          \n",
      " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
      " 13                -1  1    378624  models.common.BottleneckCSP             [512, 256, 1, False]          \n",
      " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
      " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
      " 17                -1  1     95104  models.common.BottleneckCSP             [256, 128, 1, False]          \n",
      " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
      " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
      " 20                -1  1    313088  models.common.BottleneckCSP             [256, 256, 1, False]          \n",
      " 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
      " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
      " 23                -1  1   1248768  models.common.BottleneckCSP             [512, 512, 1, False]          \n",
      " 24      [17, 20, 23]  1     16182  models.yolo.Detect                      [1, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [128, 256, 512]]\n",
      "Model Summary: 283 layers, 7255094 parameters, 7255094 gradients\n",
      "\n",
      "Adding autoShape... \n",
      "YOLOv5 ðŸš€ 2021-4-24 torch 1.8.0a0+37c1f4a CUDA:0 (NVIDIA Tegra X1, 3964.07421875MB)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model   = LicensePlateDetection()\n",
    "ocr     = OpticalCharacterRecognition()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detection(image):\n",
    "    '''\n",
    "    Detection license plate\n",
    "    and filter clasess, confidence\n",
    "    Args:\n",
    "        image(np.array): image for cropped\n",
    "    return:\n",
    "        result(tuple): (\n",
    "                image_cropped(np.array): image croped,\n",
    "                confidence(float): confidence level,\n",
    "                bbox(list): bbox detection [x_min, y_min, x_max, y_max]\n",
    "            )\n",
    "\n",
    "    '''\n",
    "    result_detection = model.prediction(image)\n",
    "    license_plate = model.filter_and_crop(\n",
    "        img=image, results=result_detection, min_confidence=0.0\n",
    "    )\n",
    "    if len(license_plate[0]) >=1 and license_plate[1] > 0 and len(license_plate[2]) == 4:\n",
    "        print(f'Got license plate detection confidence : {round(license_plate[1], 2)} %')\n",
    "    else: print(f'License plate not found')\n",
    "    return license_plate\n",
    "\n",
    "def resize(image, height_percent=180, width_percent=180):\n",
    "\t'''\n",
    "\tresize image by percent\n",
    "    Args:\n",
    "        image(np.array): image\n",
    "        height_percent(int): percentage height\n",
    "        width_percent(int): percentage width\n",
    "    Return:\n",
    "        image(np.array): image resized\n",
    "\t'''\n",
    "\theight = int(image.shape[0] * height_percent / 100)\n",
    "\twidth = int(image.shape[1] * width_percent / 100)\n",
    "\tdim = (width, height)\n",
    "\tnew_img = cv2.resize(image, dim, interpolation = cv2.INTER_AREA)\n",
    "\tprint(f'Resize image to : {new_img.shape}')\n",
    "\treturn new_img\n",
    "\n",
    "def detect_char(image, output=False):\n",
    "    '''\n",
    "    Detection charcters text in image\n",
    "    Args:\n",
    "        image(np.array): image.\n",
    "        output(boolean): output detection default (output=False)\n",
    "    Return:\n",
    "        result(boolean|list): result detection character\n",
    "    '''\n",
    "    detected_char = ocr.detect_char(image)\n",
    "    if detected_char[0]:\n",
    "        print(f'Found text in image : {\" \".join([str(i) for i in detected_char[0]])}')\n",
    "    else:\n",
    "        print(f'Not found text in image')\n",
    "\n",
    "    if output:\n",
    "        results = detected_char[0][0]\n",
    "    else: \n",
    "        if detected_char[0]: results = True\n",
    "        else: results = False\n",
    "    return results\n",
    "\n",
    "def read_text(image, position_text='horizontal', clasess_name='license_plate'):\n",
    "    '''\n",
    "    Set methods and value config ocr\n",
    "    methods view schema/config_ocr.py\n",
    "    Args:\n",
    "        image(np.array): image for read text\n",
    "        position_text(str): position text vertical/horizontal (default=vertical)\n",
    "        clasess_name(str): clasess name read text (default=license_plate)\n",
    "    Retrun:\n",
    "        result(list): [([[28, 32], [52, 32], [52, 64], [28, 64]], 'text', 0.9846626687831872)]\n",
    "    '''\n",
    "    if position_text == 'horizontal':\n",
    "        config = ConfigOcr(\n",
    "            beam_width      = 8,\n",
    "            batch_size      = 10,\n",
    "            text_threshold  = 0.5,\n",
    "            link_threshold  = 0.9,\n",
    "            low_text        = 0.4,\n",
    "            slope_ths       = 0.9,\n",
    "            mag_ratio \t\t= 1,\n",
    "            add_margin\t\t= 0.5,\n",
    "            width_ths       = 0.5\n",
    "        )\n",
    "    elif position_text == 'vertical':\n",
    "        config = ConfigOcr(\n",
    "            batch_size  \t= 10,\n",
    "            text_threshold \t= 0.2,\n",
    "            link_threshold \t= 0.9,\n",
    "            low_text \t\t= 0.4,\n",
    "            add_margin\t\t= 0\n",
    "        )\n",
    "\n",
    "    results = ocr.ocr_image(image=image, config=config)\n",
    "    if position_text == 'horizontal': results.sort(reverse=False)\n",
    "    else : results = results\n",
    "    print(f'Ocr {clasess_name} : {\" \".join([i[1] for i in results])}')\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Got license plate detection confidence : 0.9 %\n"
     ]
    }
   ],
   "source": [
    "image = cv2.imread('../assets/img/5.jpeg')\n",
    "try:\n",
    "    license_plate = detection(image)\n",
    "except:\n",
    "    license_plate = (np.array([], dtype=np.uint8), 0, list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=98x48 at 0x7F28529358>"
      ],
      "image/png": "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\n"
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "# Get image crop (license plate) and get bbox (license plate)\n",
    "if len(license_plate[0]) >=1 and\\\n",
    "    license_plate[1] > 0 and\\\n",
    "    len(license_plate[2]) == 4:\n",
    "    image_license_plate, bbox_license_plate = license_plate[0], license_plate[2]\n",
    "else:\n",
    "    # Get manual crop container characteristic with detect char and filter bbox character\\\n",
    "    image_license_plate, bbox_license_plate = image, None\n",
    "\n",
    "Image.fromarray(cv2.cvtColor(image_license_plate, cv2.COLOR_BGR2RGB))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Resize image to : (96, 200, 3)\n",
      "Found text in image : [31, 49, 23, 51] [125, 181, 31, 67]\n",
      "Ocr license_plate : 8 1549 RFS\n"
     ]
    }
   ],
   "source": [
    "def process_license_plate(image_detection, bbox):\n",
    "    if bbox:\n",
    "        # Resize if width > 120\n",
    "        image_crop = resize(image_detection.copy(), 200, 205) if image_detection.shape[1] < 120 else image_detection\n",
    "        # Detect character in text\n",
    "        detected_char = detect_char(image_crop, output=False)\n",
    "        # Get image if character not found in image\n",
    "        image_crop = resize(image_detection, 90, 100) if not detected_char else image_crop\n",
    "    else:\n",
    "        image_crop = resize(image_detection, 90, 100)\n",
    "    # Process OCR\n",
    "    results_ocr = read_text(image_crop, position_text='horizontal', clasess_name='license_plate')\n",
    "    \n",
    "    return results_ocr\n",
    "\n",
    "results_ocr = process_license_plate(image_license_plate, bbox_license_plate)\n",
    "\n"
   ]
  },
  {
   "source": [
    "# Text Processing"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_text_conf(text_conf):\n",
    "    '''\n",
    "    Remove space in list text_conf and add create new list\n",
    "    Args:\n",
    "        text_conf(list): text condidence result ocr -> [['8 1549 RFS', 0.7276318370729566]]\n",
    "    Return:\n",
    "        new_text_conf(list): new text confidence -> [['8', 0.7276318370729566], ['1549', 0.7276318370729566], ['RFS', 0.7276318370729566]]\n",
    "    '''\n",
    "    new_text_conf = list()\n",
    "    for text, conf in text_conf:\n",
    "        remove_space = text.split(' ')\n",
    "        for word in remove_space:\n",
    "            if word.isalnum():\n",
    "                new_text_conf.append([word, conf])\n",
    "    return new_text_conf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[['8', 0.7276318370729566], ['1549', 0.7276318370729566], ['RFS', 0.7276318370729566]]\n"
     ]
    }
   ],
   "source": [
    "text_conf_list  = [[i[1], i[2]] for i in results_ocr]\n",
    "filtered_text = filter_text_conf(text_conf_list)\n",
    "print(filtered_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from similarity.weighted_levenshtein import WeightedLevenshtein\n",
    "from similarity.weighted_levenshtein import CharacterSubstitutionInterface\n",
    "\n",
    "'''\n",
    "Add cost substituting word in compnames and result ocr\n",
    "'''\n",
    "class AreaCodeCharacterSubstitution(CharacterSubstitutionInterface):\n",
    "\tdef cost(self, char_true, char_false):\n",
    "\t\t# print(c0)\n",
    "\t\tif char_true == 'B' and char_false == '8': return 0.5\n",
    "\t\treturn 1.0\n",
    "weighted_levenshtein_area_code = WeightedLevenshtein(AreaCodeCharacterSubstitution())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'area_code': ['B', 0.8638159185364783]}"
      ]
     },
     "metadata": {},
     "execution_count": 43
    }
   ],
   "source": [
    "# get area code\n",
    "\n",
    "filtered_text = [['8', 0.7276318370729566], ['1549', 0.7276318370729566], ['RFS', 0.7276318370729566]]\n",
    "\n",
    "license_plate_dict = dict()\n",
    "\n",
    "text_list   = [text for text,_ in filtered_text]\n",
    "conf_list   = [conf for _,conf in filtered_text]\n",
    "index       = [i for i,x in enumerate(text_list) if len(x) <= 2 and not x.isnumeric()]\n",
    "if index:\n",
    "    for idx in index:\n",
    "        if text_list[idx] in KODE_WILAYAH_JSON:\n",
    "            license_plate_dict.update({'area_code': [text_list[idx], conf_list[idx]]})\n",
    "            break\n",
    "else: get_area_code_more()\n",
    "\n",
    "def get_area_code_more():\n",
    "    '''\n",
    "    filtered text with minimum pattren area code\n",
    "    Get Area Code with algoritm weighted_levenshtein\n",
    "    and update confidence (conf+1)/2\n",
    "    '''\n",
    "    min_ratio = 10\n",
    "    temp = str()\n",
    "    conf_i = float()\n",
    "\n",
    "    for text, conf in filtered_text:\n",
    "        if len(text) in range(1, 4):\n",
    "            for area in KODE_WILAYAH_JSON:\n",
    "                ratio = weighted_levenshtein_area_code.distance(area, text)\n",
    "                if ratio < min_ratio:\n",
    "                    min_ratio = ratio\n",
    "                    temp = area\n",
    "                    conf_i = (conf+1)/2\n",
    "                else:\n",
    "                    min_ratio = min_ratio\n",
    "                    temp = temp\n",
    "                    conf_i = conf_i\n",
    "    if min_ratio < 1.5 and temp in KODE_WILAYAH_JSON:\n",
    "        license_plate_dict.update({'area_code': [temp, conf_i]})\n",
    "    else:\n",
    "        license_plate_dict.update({'area_code': ['', 0]})\n",
    "license_plate_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'A'"
   ]
  }
 ]
}